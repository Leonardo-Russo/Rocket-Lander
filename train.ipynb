{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from rocket import Rocket\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    task = 'landing'\n",
    "    max_m_episode = 800000\n",
    "    max_steps = 800\n",
    "\n",
    "    # Create a vectorized environment\n",
    "    env_fn = lambda: Rocket(task=task, max_steps=max_steps)\n",
    "    env = make_vec_env(env_fn, n_envs=1)\n",
    "\n",
    "    # Load the model or create a new one\n",
    "    model_path = os.path.join('Models', task + '_ppo')\n",
    "    if os.path.exists(model_path + \".zip\"):\n",
    "        model = PPO.load(model_path, env=env)  # Set the environment here\n",
    "    else:\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=100000, progress_bar=True)  # Adjust the number of timesteps as needed\n",
    "\n",
    "    # Save the model\n",
    "    model_path = os.path.join('models', task + '_ppo')\n",
    "    model.save(model_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
